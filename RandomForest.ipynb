{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.0-py3-none-any.whl (302 kB)\n",
      "\u001b[K     |████████████████████████████████| 302 kB 61.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 3.1 kB/s  eta 0:00:0101\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=56a947aaf9ba78a6c7f6e4d6a7f3aaf98a13f745d1f49679749121f39cafbcb5\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, threadpoolctl, scipy, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.0 scikit-learn-0.23.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (273, 12)\n",
      "Training Labels Shape: (273,)\n",
      "Testing Features Shape: (92, 12)\n",
      "Testing Labels Shape: (92,)\n",
      "[[6.7000e+01 6.6483e+01 5.1700e-01]\n",
      " [3.5000e+01 3.9123e+01 4.1230e+00]\n",
      " [4.6000e+01 4.3478e+01 2.5220e+00]\n",
      " [4.5000e+01 4.8278e+01 3.2780e+00]\n",
      " [5.1000e+01 4.9971e+01 1.0290e+00]\n",
      " [6.5000e+01 6.2896e+01 2.1040e+00]\n",
      " [4.5000e+01 4.3682e+01 1.3180e+00]\n",
      " [5.3000e+01 5.2361e+01 6.3900e-01]\n",
      " [6.7000e+01 6.4445e+01 2.5550e+00]\n",
      " [5.2000e+01 4.8332e+01 3.6680e+00]\n",
      " [4.0000e+01 4.1387e+01 1.3870e+00]\n",
      " [4.7000e+01 4.7015e+01 1.5000e-02]\n",
      " [5.6000e+01 4.5210e+01 1.0790e+01]\n",
      " [4.9000e+01 4.9226e+01 2.2600e-01]\n",
      " [5.6000e+01 5.3173e+01 2.8270e+00]\n",
      " [4.4000e+01 4.7980e+01 3.9800e+00]\n",
      " [4.7000e+01 4.0980e+01 6.0200e+00]\n",
      " [4.9000e+01 5.4172e+01 5.1720e+00]\n",
      " [5.2000e+01 5.0480e+01 1.5200e+00]\n",
      " [4.3000e+01 4.4966e+01 1.9660e+00]\n",
      " [3.8000e+01 4.2930e+01 4.9300e+00]\n",
      " [5.9000e+01 5.7702e+01 1.2980e+00]\n",
      " [5.1000e+01 4.9145e+01 1.8550e+00]\n",
      " [6.3000e+01 5.6911e+01 6.0890e+00]\n",
      " [5.7000e+01 5.8464e+01 1.4640e+00]\n",
      " [6.3000e+01 6.3384e+01 3.8400e-01]\n",
      " [6.8000e+01 6.6721e+01 1.2790e+00]\n",
      " [4.8000e+01 5.2128e+01 4.1280e+00]\n",
      " [4.5000e+01 4.4961e+01 3.9000e-02]\n",
      " [4.6000e+01 4.5099e+01 9.0100e-01]\n",
      " [4.7000e+01 4.5711e+01 1.2890e+00]\n",
      " [6.0000e+01 5.6139e+01 3.8610e+00]\n",
      " [4.4000e+01 4.3222e+01 7.7800e-01]\n",
      " [5.3000e+01 4.2636e+01 1.0364e+01]\n",
      " [6.8000e+01 6.2373e+01 5.6270e+00]\n",
      " [5.4000e+01 5.7870e+01 3.8700e+00]\n",
      " [4.6000e+01 4.4129e+01 1.8710e+00]\n",
      " [3.5000e+01 3.7970e+01 2.9700e+00]\n",
      " [4.6000e+01 4.7872e+01 1.8720e+00]\n",
      " [4.8000e+01 5.0068e+01 2.0680e+00]\n",
      " [6.2000e+01 6.8950e+01 6.9500e+00]\n",
      " [4.2000e+01 4.2749e+01 7.4900e-01]\n",
      " [3.1000e+01 3.7601e+01 6.6010e+00]\n",
      " [5.6000e+01 5.1328e+01 4.6720e+00]\n",
      " [6.2000e+01 5.8877e+01 3.1230e+00]\n",
      " [6.8000e+01 6.2935e+01 5.0650e+00]\n",
      " [4.7000e+01 4.9565e+01 2.5650e+00]\n",
      " [5.1000e+01 4.8348e+01 2.6520e+00]\n",
      " [4.6000e+01 4.4158e+01 1.8420e+00]\n",
      " [4.4000e+01 4.4441e+01 4.4100e-01]\n",
      " [6.5000e+01 6.2408e+01 2.5920e+00]\n",
      " [4.5000e+01 4.5766e+01 7.6600e-01]\n",
      " [6.0000e+01 5.6201e+01 3.7990e+00]\n",
      " [6.0000e+01 5.7713e+01 2.2870e+00]\n",
      " [6.3000e+01 6.7137e+01 4.1370e+00]\n",
      " [3.9000e+01 4.3147e+01 4.1470e+00]\n",
      " [4.2000e+01 4.2634e+01 6.3400e-01]\n",
      " [3.8000e+01 4.4388e+01 6.3880e+00]\n",
      " [4.5000e+01 4.0020e+01 4.9800e+00]\n",
      " [4.9000e+01 4.4844e+01 4.1560e+00]\n",
      " [7.7000e+01 6.9927e+01 7.0730e+00]\n",
      " [4.4000e+01 4.5255e+01 1.2550e+00]\n",
      " [5.1000e+01 4.9317e+01 1.6830e+00]\n",
      " [4.7000e+01 4.5220e+01 1.7800e+00]\n",
      " [6.1000e+01 6.1066e+01 6.6000e-02]\n",
      " [5.4000e+01 5.0418e+01 3.5820e+00]\n",
      " [6.2000e+01 6.1075e+01 9.2500e-01]\n",
      " [4.7000e+01 4.6675e+01 3.2500e-01]\n",
      " [7.8000e+01 7.0188e+01 7.8120e+00]\n",
      " [4.7000e+01 5.0682e+01 3.6820e+00]\n",
      " [4.9000e+01 4.5735e+01 3.2650e+00]\n",
      " [6.9000e+01 6.7501e+01 1.4990e+00]\n",
      " [4.6000e+01 4.2483e+01 3.5170e+00]\n",
      " [6.7000e+01 6.5863e+01 1.1370e+00]\n",
      " [4.9000e+01 4.7750e+01 1.2500e+00]\n",
      " [7.1000e+01 6.3574e+01 7.4260e+00]\n",
      " [4.4000e+01 5.1768e+01 7.7680e+00]\n",
      " [4.7000e+01 4.9460e+01 2.4600e+00]\n",
      " [4.7000e+01 4.9311e+01 2.3110e+00]\n",
      " [3.8000e+01 4.4782e+01 6.7820e+00]\n",
      " [4.6000e+01 4.6703e+01 7.0300e-01]\n",
      " [6.1000e+01 6.1048e+01 4.8000e-02]\n",
      " [4.5000e+01 4.7103e+01 2.1030e+00]\n",
      " [5.6000e+01 6.1712e+01 5.7120e+00]\n",
      " [4.9000e+01 5.1603e+01 2.6030e+00]\n",
      " [4.1000e+01 3.7174e+01 3.8260e+00]\n",
      " [4.3000e+01 4.4825e+01 1.8250e+00]\n",
      " [6.4000e+01 6.3652e+01 3.4800e-01]\n",
      " [4.8000e+01 4.1449e+01 6.5510e+00]\n",
      " [6.0000e+01 6.2193e+01 2.1930e+00]\n",
      " [4.4000e+01 4.2091e+01 1.9090e+00]\n",
      " [5.1000e+01 4.8524e+01 2.4760e+00]]\n",
      "Mean Absolute Error: 3.01 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data and display first 5 rows\n",
    "features = pd.read_csv('TemperatureData.csv')\n",
    "\n",
    "\n",
    "# print(features.head(5))\n",
    "# print('The shape of our features is:', features.shape)\n",
    "# features.describe()\n",
    "\n",
    "# Use datetime for dealing with dates\n",
    "import datetime\n",
    "\n",
    "# Get years, months, and days\n",
    "years = features['Year']\n",
    "months = features['Month']\n",
    "days = features['Day']\n",
    "\n",
    "# List and then convert to datetime object\n",
    "dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "\n",
    "\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Set up the plotting layout\n",
    "#fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize = (8,8))\n",
    "#fig.autofmt_xdate(rotation = 45)\n",
    "\n",
    "# Actual max temperature measurement\n",
    "#ax1.plot(dates, features['Temp'])\n",
    "#ax1.set_xlabel(''); ax1.set_ylabel('Temperature (F)'); ax1.set_title('Temp')\n",
    "\n",
    "# Temperature from 1 day ago\n",
    "#ax2.plot(dates, features['Temp-1'])\n",
    "#ax2.set_xlabel(''); ax2.set_ylabel('Temperature (F)'); ax2.set_title('Temp:-1')\n",
    "\n",
    "# Temperature from 2 days ago\n",
    "#ax3.plot(dates, features['Temp-2'])\n",
    "#ax3.set_xlabel('Date'); ax3.set_ylabel('Temperature (F)'); ax3.set_title('Temp:-2')\n",
    "\n",
    "#don't plot\n",
    "# plt.tight_layout(pad=3)\n",
    "\n",
    "\n",
    "# One-hot encode weekdays (transform weekdays to binary columns (using pandas get_dummies)\n",
    "#print(pd.get_dummies(features))\n",
    "\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# create Labels array of the target variable (aka label, dependent variable)\n",
    "labels = np.array(features['Temp'])\n",
    "\n",
    "# Remove this column from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('Temp', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert remaining data to a numpy array (also called features)\n",
    "features = np.array(features)\n",
    "\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "listx = np.stack((test_labels, predictions, errors), axis=1)\n",
    "print(listx)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
